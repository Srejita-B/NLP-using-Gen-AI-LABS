{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b048700",
   "metadata": {},
   "source": [
    "# Create a feedforward neural network for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbac2a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Step 2: Generate some random data for demonstration\n",
    "np.random.seed(0)\n",
    "X = np.random.rand(100, 2)  # Features (2 input neurons)   --shape of the array\n",
    "y = (X[:, 0] + X[:, 1] > 1).astype(int)  # Binary target variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73e18b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SREJITA\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "## Step 3: Create a Sequential model\n",
    "model_srejita = Sequential()\n",
    "\n",
    "# Step 4: Add layers to the model\n",
    "model_srejita.add(Dense(4, input_dim=2, activation='relu'))  # Hidden layer with 3 neurons   input dimension=no of cols =2\n",
    "model_srejita.add(Dense(1, activation='sigmoid'))  # Output layer with 1 neuron (binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81fc7b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4836 - loss: 0.6914  \n",
      "Epoch 2/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5679 - loss: 0.6862 \n",
      "Epoch 3/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5258 - loss: 0.6930 \n",
      "Epoch 4/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5440 - loss: 0.6835 \n",
      "Epoch 5/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5042 - loss: 0.6896 \n",
      "Epoch 6/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5529 - loss: 0.6810 \n",
      "Epoch 7/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5318 - loss: 0.6793 \n",
      "Epoch 8/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6046 - loss: 0.6727 \n",
      "Epoch 9/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5829 - loss: 0.6820 \n",
      "Epoch 10/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6653 - loss: 0.6690 \n",
      "Epoch 11/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6510 - loss: 0.6718 \n",
      "Epoch 12/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5550 - loss: 0.6826 \n",
      "Epoch 13/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6300 - loss: 0.6718 \n",
      "Epoch 14/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6446 - loss: 0.6693 \n",
      "Epoch 15/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6204 - loss: 0.6647 \n",
      "Epoch 16/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6289 - loss: 0.6644 \n",
      "Epoch 17/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6254 - loss: 0.6639 \n",
      "Epoch 18/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6442 - loss: 0.6546 \n",
      "Epoch 19/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6346 - loss: 0.6587 \n",
      "Epoch 20/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6056 - loss: 0.6632 \n",
      "Epoch 21/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6110 - loss: 0.6586 \n",
      "Epoch 22/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6511 - loss: 0.6522 \n",
      "Epoch 23/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6032 - loss: 0.6586 \n",
      "Epoch 24/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6240 - loss: 0.6525 \n",
      "Epoch 25/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6156 - loss: 0.6585 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.6166 - loss: 0.6546   \n",
      "Loss: 0.6538\n",
      "Accuracy: 63.00%\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Compile the model\n",
    "model_srejita.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Step 6: Train the model\n",
    "model_srejita.fit(X, y, epochs=25, batch_size=20)\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "loss, accuracy = model_srejita.evaluate(X, y)\n",
    "print(f'Loss: {loss:.4f}')\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea06242",
   "metadata": {},
   "source": [
    "# Create a neural network model by your own name with a random input fn of shape 300X4 for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb7b0115",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SREJITA\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Step 2: Generate some random data for demonstration\n",
    "np.random.seed(0)\n",
    "X = np.random.rand(300, 4)  # Features (4 input neurons)   --shape of the array\n",
    "y = (X[:, 0] + X[:, 1] > 1).astype(int)  # Binary target variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e322b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SREJITA\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "## Step 3: Create a Sequential model\n",
    "model_srejita = Sequential()\n",
    "\n",
    "# Step 4: Add layers to the model\n",
    "model_srejita.add(Dense(3, input_dim=4, activation='relu'))  # Hidden layer with 3 neurons   input dimension=no of cols =4\n",
    "model_srejita.add(Dense(1, activation='sigmoid'))  # Output layer with 1 neuron (binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54f3872b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5777 - loss: 0.7181\n",
      "Epoch 2/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5251 - loss: 0.7323 \n",
      "Epoch 3/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4999 - loss: 0.7286\n",
      "Epoch 4/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5783 - loss: 0.6950 \n",
      "Epoch 5/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4897 - loss: 0.7224 \n",
      "Epoch 6/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5101 - loss: 0.7153 \n",
      "Epoch 7/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5675 - loss: 0.6894 \n",
      "Epoch 8/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5283 - loss: 0.7104 \n",
      "Epoch 9/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4953 - loss: 0.7028 \n",
      "Epoch 10/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5025 - loss: 0.7026\n",
      "Epoch 11/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4857 - loss: 0.7080 \n",
      "Epoch 12/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5169 - loss: 0.6993 \n",
      "Epoch 13/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5343 - loss: 0.6861 \n",
      "Epoch 14/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5094 - loss: 0.6976 \n",
      "Epoch 15/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5167 - loss: 0.6877 \n",
      "Epoch 16/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4839 - loss: 0.6914 \n",
      "Epoch 17/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5121 - loss: 0.6887 \n",
      "Epoch 18/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4771 - loss: 0.6927 \n",
      "Epoch 19/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4992 - loss: 0.6924 \n",
      "Epoch 20/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4960 - loss: 0.6923 \n",
      "Epoch 21/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5074 - loss: 0.6907 \n",
      "Epoch 22/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5549 - loss: 0.6809 \n",
      "Epoch 23/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5314 - loss: 0.6786 \n",
      "Epoch 24/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4935 - loss: 0.6985 \n",
      "Epoch 25/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4765 - loss: 0.6896 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5553 - loss: 0.6806  \n",
      "Loss: 0.6828\n",
      "Accuracy: 53.67%\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Compile the model\n",
    "model_srejita.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Step 6: Train the model\n",
    "model_srejita.fit(X, y, epochs=25, batch_size=20)\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "loss, accuracy = model_srejita.evaluate(X, y)\n",
    "print(f'Loss: {loss:.4f}')\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74ef08b",
   "metadata": {},
   "source": [
    "# Write a python code using keras to perfrom linear regression on randomly generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8cd8fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SREJITA\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Generate some random data for demonstration\n",
    "np.random.seed(0)\n",
    "X = np.random.rand(300, 1)  # Features (2 input neurons)   --shape of the array\n",
    "y = 8*X+10  # Binary target variable \n",
    "## Step 3: Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Step 4: Add layers to the model\n",
    "model.add(Dense(1, input_dim=1))  \n",
    "\n",
    "# Step 5: Compile the model\n",
    "model.compile(loss='mse', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3074b199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1acc5ae75e0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6: Train the model\n",
    "model.fit(X, y, epochs=200, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e7fbf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.04824874550104141\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X,y)\n",
    "plt.plot(X,model.predict(X),color='red')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Linear Regression with Keras')\n",
    "plt.show()\n",
    "print(\"loss\",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "70bbd3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Sample text data\n",
    "text = \"anna life changes you change is constant\"\n",
    "\n",
    "# Create a vocabulary\n",
    "vocab = sorted(set(text))\n",
    "\n",
    "# Create mappings from characters to indices and vice versa\n",
    "char_to_idx = {char: idx for idx, char in enumerate(vocab)}\n",
    "idx_to_char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1c069ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - loss: 2.7412\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 2.4827\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600ms/step - loss: 1.8065\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - loss: 2.0245\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - loss: 3.1622\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - loss: 2.1893\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 1.6095\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - loss: 1.2571\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 1.2226\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - loss: 1.0421\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - loss: 0.9508\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - loss: 0.8246\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 0.6674\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - loss: 0.4614\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.4207\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - loss: 0.3738\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 0.3137\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - loss: 0.2851\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.2669\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 0.2497\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - loss: 0.2319\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.2157\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 0.2020\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - loss: 0.1904\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 0.1803\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step - loss: 0.1712\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.1628\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - loss: 0.1549\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - loss: 0.1474\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - loss: 0.1402\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - loss: 0.1334\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 0.1269\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.1209\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - loss: 0.1152\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - loss: 0.1099\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step - loss: 0.1049\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - loss: 0.1003\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - loss: 0.0961\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - loss: 0.0920\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - loss: 0.0882\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - loss: 0.0845\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - loss: 0.0810\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - loss: 0.0776\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - loss: 0.0743\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - loss: 0.0711\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0680\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - loss: 0.0651\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 0.0622\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - loss: 0.0595\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - loss: 0.0568\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - loss: 0.0543\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - loss: 0.0519\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - loss: 0.0497\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - loss: 0.0475\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 0.0455\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0436\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - loss: 0.0418\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - loss: 0.0401\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - loss: 0.0385\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - loss: 0.0369\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - loss: 0.0354\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - loss: 0.0340\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 0.0326\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - loss: 0.0313\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.0300\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - loss: 0.0288\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 0.0276\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - loss: 0.0264\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - loss: 0.0253\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - loss: 0.0242\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.0232\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - loss: 0.0221\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - loss: 0.0212\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - loss: 0.0202\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0193\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - loss: 0.0184\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0175\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - loss: 0.0167\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 0.0159\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - loss: 0.0152\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0145\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511ms/step - loss: 0.0138\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 0.0131\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0125\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step - loss: 0.0119\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - loss: 0.0113\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 0.0108\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0103\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.0098\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - loss: 0.0094\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0089\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 0.0085\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - loss: 0.0082\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 0.0078\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - loss: 0.0075\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.0071\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0068\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0066\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0063\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1acd1c04c10>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert text to numerical data\n",
    "text_as_int = np.array([char_to_idx[char] for char in text])\n",
    "\n",
    "# Define the RNN model\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024\n",
    "\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=None),\n",
    "        tf.keras.layers.SimpleRNN(rnn_units, return_sequences=True, recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = build_model(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
    "\n",
    "# Define the number of training epochs\n",
    "num_epochs = 100\n",
    "\n",
    "# Reshape input data to include batches of sequences\n",
    "input_text = text_as_int[:-1]\n",
    "target_text = text_as_int[1:]\n",
    "input_text = np.expand_dims(input_text, axis=0)\n",
    "target_text = np.expand_dims(target_text, axis=0)\n",
    "\n",
    "# Train the model\n",
    "model.fit(input_text, target_text, epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0056521a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anna iliysfl y o lsttchh ynannsanliolooanglanl nluianesicng uc cyteacto ye fnnilngntsans onieocl to hol ytfiuani cnfei yeignceanofananiieeegglihtanhltnu  ctin fniygsttoi gcang stlccsio  fcnggo fiafonuestiestiyhahn lyinosygoeyonflcosiyhlytufoilecsyuesanoiin feelchtuofu iyghutoflhanfe hihanihfe o hfuyecihetanfinolieeannfcannefocaeuynotucgfl uughonoiigunanc uanntiuueannuuligesthsylhfif sssu gsgesoofueanhonhelnni nneshnnnnohhfifcanfgysnnietogelctangifctfeictnelianuuanlanfyunnnlsifugnnstotenningshscfnnsoiteannuylttllinn ngessiesfuhytcteelnnglgstysog giisgegnanhlftselchl slfyeygfflheuffoluselggul iyliyituue  lcoohfs hsolfcclihylchuhocllhii tay canosociuhce oulyflt uciisusantngoliyntecfnchn anlliftan iicoyulainsancuhgohafnfuyocnnninouctihy yyesnneaney g  fnfiggennosenanocyanlnfcnhnneannnano   ceu snefhuunnnahicanntf giglecgfanansentiegin t ynnu anghan eulun hslycu lcyliyilc hlscoacsnuul ehf htannalanthntannhnctanongtnsosenelyans ueneccylgnnthafnsue cigtutlannuoi l angihns gynanlhnthggolyiiys ngte\n"
     ]
    }
   ],
   "source": [
    "# Generate text\n",
    "def generate_text(model, start_string, num_generate=1000):\n",
    "    input_eval = [char_to_idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    text_generated = []\n",
    "\n",
    "    #model.reset_states()\n",
    "    for _ in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated.append(idx_to_char[predicted_id])\n",
    "\n",
    "    return start_string + ''.join(text_generated)\n",
    "\n",
    "# Generate text\n",
    "generated_text = generate_text(model, start_string=\"anna\", num_generate=1000)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "edbbde26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1268.9576\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 50.4294\n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 51.2008 \n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.1866\n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3051\n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3685\n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8411\n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5110\n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7205\n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4851\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step\n",
      "test input [[[ 7]\n",
      "  [ 8]\n",
      "  [ 9]\n",
      "  [10]\n",
      "  [11]\n",
      "  [12]]\n",
      "\n",
      " [[ 8]\n",
      "  [ 9]\n",
      "  [10]\n",
      "  [11]\n",
      "  [12]\n",
      "  [13]]\n",
      "\n",
      " [[ 9]\n",
      "  [10]\n",
      "  [11]\n",
      "  [12]\n",
      "  [13]\n",
      "  [14]]\n",
      "\n",
      " [[10]\n",
      "  [11]\n",
      "  [12]\n",
      "  [13]\n",
      "  [14]\n",
      "  [15]]\n",
      "\n",
      " [[11]\n",
      "  [12]\n",
      "  [13]\n",
      "  [14]\n",
      "  [15]\n",
      "  [16]]]\n",
      "Predicted Output:\n",
      "[10.598978 11.59873  12.598482 13.598236 14.597988]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "\n",
    "# Generate some sample data\n",
    "X = np.array([[i+j for j in range(5)] for i in range(100)])\n",
    "y = np.array([i+5 for i in range(100)])\n",
    "\n",
    "# Reshape the data for RNN input (samples, time steps, features)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# Define the RNN model\n",
    "model = Sequential([\n",
    "    SimpleRNN(units=32, input_shape=(X.shape[1], X.shape[2]), activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=10, batch_size=8)\n",
    "\n",
    "# Test the model\n",
    "test_input = np.array([[i+j for j in range(6)] for i in range(7, 12)])\n",
    "test_input = test_input.reshape((test_input.shape[0], test_input.shape[1], 1))\n",
    "predicted_output = model.predict(test_input)\n",
    "\n",
    "# Print the predicted output\n",
    "print(\"test input\",test_input)\n",
    "print(\"Predicted Output:\")\n",
    "print(predicted_output.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f2a3f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
